# Ethics Committee - Example Use Cases

This document provides example questions and scenarios to explore with the Ethics Committee panel.

## Classic Philosophical Dilemmas

### The Trolley Problem

**Question**: A runaway trolley is heading toward five people tied to the tracks. You can pull a lever to divert it to a side track where it will kill one person instead. Should you pull the lever?

**Expected Perspectives**:

- **Utilitarian**: Yes, five lives saved vs. one lost maximizes utility
- **Deontologist**: Possibly no—pulling the lever makes you causally responsible for killing
- **Virtue Ethicist**: What would a person of practical wisdom do? Context matters
- **Care Ethicist**: Who are these people? What relationships exist?
- **Rights Theorist**: You may not violate the one person's right to life
- **Pragmatist**: What will actually happen? Is this a realistic scenario?

### The Lying Promise

**Question**: You can save someone's life by making a promise you know you cannot keep. Should you lie?

**Expected Perspectives**:

- **Utilitarian**: Yes, if the life saved outweighs the harm of the broken promise
- **Deontologist**: No, lying violates the categorical imperative
- **Virtue Ethicist**: Depends on the character of the person and the circumstances
- **Care Ethicist**: What is my relationship to this person? What do they need?

## Contemporary AI Ethics

### Autonomous Vehicle Decision

**Question**: How should a self-driving car be programmed to respond in an unavoidable accident scenario where it must choose between harming passengers or pedestrians?

**Expected Perspectives**:

- **AI Ethics Specialist**: This is a value alignment problem. Who decides? How is the decision made transparent?
- **Utilitarian**: Minimize total harm across all scenarios
- **Deontologist**: The car should not be programmed to intentionally kill anyone
- **Rights Theorist**: Passengers consented to the risk; pedestrians did not

### Algorithmic Hiring

**Question**: A company uses an AI system to screen job applicants. The system is more accurate than human recruiters but shows slight bias against certain demographic groups. Should they use it?

**Expected Perspectives**:

- **AI Ethics Specialist**: Unacceptable—algorithmic bias perpetuates discrimination
- **Utilitarian**: Depends on the magnitude of bias vs. accuracy improvement
- **Rights Theorist**: Individuals have a right to fair consideration
- **Pragmatist**: What works better in practice? Can we fix the bias?

## Policy Questions

### Universal Healthcare

**Question**: Should the government provide universal healthcare funded by taxes?

**Expected Perspectives**:

- **Utilitarian**: If it maximizes overall health and well-being, yes
- **Rights Theorist**: Taxation is coercion; people have a right to their property
- **Care Ethicist**: Healthcare is about caring for vulnerable members of society
- **Virtue Ethicist**: Does this promote human flourishing?

### Climate Action

**Question**: Should we impose significant economic costs now to prevent climate change that will primarily harm future generations?

**Expected Perspectives**:

- **Utilitarian**: Yes, if the prevented future harm outweighs present costs
- **Deontologist**: We have duties to future generations
- **Pragmatist**: What will actually work to solve the problem?
- **Rights Theorist**: Do we have the right to impose costs on current people?

## Bioethics

### Gene Editing

**Question**: Should we allow parents to use CRISPR to edit their children's genes to prevent disease? What about to enhance traits like intelligence?

**Expected Perspectives**:

- **AI Ethics Specialist**: Similar to AI alignment—who controls the technology?
- **Utilitarian**: Prevent disease yes, enhancement depends on consequences
- **Deontologist**: Are we treating children as means to parental ends?
- **Virtue Ethicist**: Does this promote human flourishing or undermine it?

### Resource Allocation in Healthcare

**Question**: A hospital has one ventilator and two patients who need it. One is 25 years old, the other is 75. Who gets it?

**Expected Perspectives**:

- **Utilitarian**: Probably the younger patient (more life-years saved)
- **Deontologist**: Both have equal dignity; perhaps use a lottery
- **Care Ethicist**: What are the particular circumstances of each person?
- **Rights Theorist**: Both have equal rights to life

## Business Ethics

### Whistleblowing

**Question**: You discover your company is violating environmental regulations. Should you report it, knowing you'll likely lose your job?

**Expected Perspectives**:

- **Deontologist**: You have a duty to tell the truth and prevent harm
- **Virtue Ethicist**: What would a person of integrity do?
- **Care Ethicist**: What responsibilities do you have to colleagues who depend on the company?
- **Pragmatist**: What will actually improve the situation?

## Personal Dilemmas

### The White Lie

**Question**: Your friend asks if you like their new haircut. You think it looks terrible. Should you lie to spare their feelings?

**Expected Perspectives**:

- **Deontologist**: No, lying is wrong even for good reasons
- **Utilitarian**: Yes, if the harm of hurt feelings outweighs the minor lie
- **Virtue Ethicist**: A person of tact and kindness might find a gentle truth
- **Care Ethicist**: What does this relationship need? How can I respond with care?

## How to Use These Examples

1. **Present the scenario** to your AI system configured with the Ethics Committee personas
2. **Ask each persona** to respond from their ethical framework
3. **Compare the responses** to understand how different frameworks lead to different conclusions
4. **Explore the tensions** between competing values and principles
5. **Develop your own ethical reasoning** by engaging with these diverse perspectives
